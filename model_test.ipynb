{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5df963ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from data_loaders.pulja_data_loader import PuljaDataLoader\n",
    "from models._20220520_00 import UserModel\n",
    "from models.utils import collate_fn\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    from torch.cuda import FloatTensor, LongTensor\n",
    "    torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "else:\n",
    "    from torch import FloatTensor, LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24bdc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seq_len = 100\n",
    "train_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61053bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PuljaDataLoader(seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446ef22d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.num_c, dataset.num_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fbc6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.c_seqs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2878881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(dataset) * train_ratio)\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(\n",
    "    dataset, [train_size, test_size]\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=test_size, shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0197f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UserModel(dataset.num_c, dataset.num_d, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efee8fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UserModel(\n",
       "  (D1): Embedding(7, 1)\n",
       "  (D2): Embedding(7, 50)\n",
       "  (gru): GRU(100, 50, batch_first=True)\n",
       "  (linear_1): Sequential(\n",
       "    (0): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       "  (linear_2): Sequential(\n",
       "    (0): Linear(in_features=150, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=50, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8206f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.,  0.,  0.,  ..., -0., -0., -0.],\n",
      "        [24., 24., 24.,  ..., 35., 35., 35.],\n",
      "        [ 2.,  2.,  2.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [28., 28., 22.,  ..., 17., 17., 17.],\n",
      "        [26., 26., 26.,  ..., 30., 30., 30.],\n",
      "        [21., 21., 21.,  ...,  9.,  9.,  9.]]), tensor([[0., 0., 0.,  ..., -0., -0., -0.],\n",
      "        [2., 2., 2.,  ..., 1., 2., 2.],\n",
      "        [2., 2., 3.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [2., 2., 4.,  ..., 3., 3., 5.],\n",
      "        [1., 1., 1.,  ..., 2., 2., 2.],\n",
      "        [2., 0., 1.,  ..., 1., 0., 1.]]), tensor([[0.0000, 0.0000, 0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [0.0000, 0.1765, 0.0000,  ..., 0.9020, 0.0000, 0.0000],\n",
      "        [1.0000, 0.0000, 0.3268,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [1.0000, 1.0000, 0.8706,  ..., 0.0000, 0.4052, 0.0000],\n",
      "        [0.0000, 0.9281, 0.0392,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.5621, 0.0000, 0.0000]]), tensor([[ 0.,  0.,  0.,  ..., -0., -0., -0.],\n",
      "        [24., 24., 21.,  ..., 35., 35., 35.],\n",
      "        [ 2.,  2.,  2.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [28., 22., 22.,  ..., 17., 17., 17.],\n",
      "        [26., 26., 26.,  ..., 30., 30., 30.],\n",
      "        [21., 21., 24.,  ...,  9.,  9.,  9.]]), tensor([[0., 0., 0.,  ..., -0., -0., -0.],\n",
      "        [2., 2., 2.,  ..., 2., 2., 0.],\n",
      "        [2., 3., 2.,  ..., -0., -0., -0.],\n",
      "        ...,\n",
      "        [2., 4., 3.,  ..., 3., 5., 3.],\n",
      "        [1., 1., 1.,  ..., 2., 2., 2.],\n",
      "        [0., 1., 0.,  ..., 0., 1., 0.]]), tensor([[0.0000, 0.0000, 0.0392,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [0.1765, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.3268, 1.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [1.0000, 0.8706, 1.0000,  ..., 0.4052, 0.0000, 1.0000],\n",
      "        [0.9281, 0.0392, 1.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]), tensor([[ True,  True,  True,  ..., False, False, False],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ..., False, False, False],\n",
      "        ...,\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True],\n",
      "        [ True,  True,  True,  ...,  True,  True,  True]]))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b44cef9e9828>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mc_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcshft_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdshft_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrshft_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_seq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\git-repositories\\knowledge-tracing-collection-pytorch\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\git-repositories\\ai-user-modeling\\models\\_20220520_00.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, c_seq, d_seq, r_seq, h_0, C_0)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;31m# v_d_seq, v_r_seq: [batch_size, seq_len, dim_v]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mv_d_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mD2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_seq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m         \u001b[0mv_r_seq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr_seq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv_r\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\git-repositories\\knowledge-tracing-collection-pytorch\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\git-repositories\\knowledge-tracing-collection-pytorch\\.venv\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         return F.embedding(\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
      "\u001b[1;32mc:\\git-repositories\\knowledge-tracing-collection-pytorch\\.venv\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1850\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1852\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1854\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have scalar type Long; but got torch.cuda.FloatTensor instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "for data in train_loader:\n",
    "    print(data)\n",
    "    \n",
    "    c_seq, d_seq, r_seq, cshft_seq, dshft_seq, rshft_seq, m_seq = data\n",
    "    \n",
    "    print(model(c_seq, d_seq, r_seq))\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc31786",
   "metadata": {},
   "outputs": [],
   "source": [
    "model(LongTensor(dataset.c_seqs[:5]), LongTensor(dataset.d_seqs[:5]), FloatTensor(dataset.r_seqs[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12a0fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_seq, beta_seq, gamma_seq, h_seq, C_seq = model(LongTensor(dataset.c_seqs[:5]), LongTensor(dataset.d_seqs[:5]), FloatTensor(dataset.r_seqs[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d394f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_seq.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
